---
title: Tech Projects
layout: default
---
# A selection of technical engineering projects

## Reinforcement Learning and Intuitive Physics

Artificial intuitive physics involves addressing computational models for "intuitive theories" of physics, reverse-engineering the theories, and implementing them in AI algorithms. The goal of the project is to implement intuitive physics engines in a simulated environment using reinforcement learning, enabling agents to interact with their surroundings that can be applied to a real-life robot. The research involves using the Pybullet and OpenAI Gym libraries for physics simulation, in addition to other libraries, and implementing different reinforcement learning algorithms from scratch, such as Proximal Policy Optimization and World Models.

# Featured Course Projects

**Bayesian Deep Learning:**
![Snapshot of aleatoric uncertainty for a computer vision dataset](aleatoric_uncertainty.jpg)
- **Project Summary:**
Research on epistemic and aleatoric uncertainties for Bayesian Deep Learning (2019). For this project, we extend the research by Alex Kendall and Yarin Gal from the paper "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?" We provide a synthesis of this paper and evaluate the claims made by the authors. We implemented pedagogical examples of neural networks with and without epistemic and aleatoric uncertainty and evaluated these models on toy regression and classification tasks, in addition to the MNIST and CIFAR-10 datasets. We also implement experiments such as the effect of model complexity on the performance of a model incorporating epistemic uncertainty, and the effect of data transformations on epistemic and aleatoric uncertainty.

[Colab notebook](https://colab.research.google.com/github/onefishy/am207_fall19_projects/blob/master/what_uncertainties/what_uncertainties_3/cheruvuria_136145_9127626_Final_Project_Submission.ipynb)

**Automated Data Engineering Workflow:**
- **Project Summary:**
Automated Data Engineering Using Dask and Luigi (2019). This project implements an automated data engineering pipeline - Given large input dataset CSV files and user-defined preferences, the data is cleaned, data types are automatically determined, and the workflow outputs a visualization HTML report (which is atomically written to the user's local file system) for the categorical and numerical variables in the dataset.

**Healthcare Streaming Data Visualization Pipeline:**
![Streaming Data Pipeline](project_streaming_data.jpg)
- **Project Summary:**
Healthcare Streaming Data Visualization Pipeline (2019). Can we predict and visualize the percent of adults who have an overweight classification in a particular region in the US based on factors such as income, gender, or race? The goal of this project was to simulate a real-life streaming application using Kibana, ElasticSearch, Kafka, and Spark for a potential use case where health care service providers and insurance organizations are consistently providing data and querying a system on the patterns in the obesity epidemic across the United States.

**Neural Cryptography:**
![Cryptography pipeline](https://github.com/riacheruvu/neural-cryptography/blob/master/Crypto-Pipeline.png)
- **Project Summary:**
Applying Convolutional Neural Networks to Cryptography (2016). As part of this project, I have successfully demonstrated an efficient neural cryptography algorithm (NCA) through tuning and implemented NCA through socket communication. I have also developed a signature/verification capability calculated based on the hidden states of the neural networks, which has not been accomplished before at the time of the project. The adopted and modified code presented in this project serves as a foundation to further research and improvements to the neural cryptography work.